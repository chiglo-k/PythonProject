# Итоговый проект по Python

## Описание
Этот проект представляет собой систему репликации данных между PostgreSQL и MySQL с использованием Apache Airflow, а также создание аналитических витрин с Apache Spark.

## Установка

1. Клонируйте репозиторий:

`bash git clone[https://github.com/chiglo-k/PythonProject/]`

2. Перейдите в директорию проекта:

выполните команду ---> `docker-compose up -d` `docker-compose up airflow-init`

**PostgreSQL(localhost:5433)**

- POSTGRES_DB: postgres
- POSTGRES_USER: airflow
- POSTGRES_PASSWORD: airflow


**MySQL(localhost:3306)**
- MYSQL_DATABASE: chinook_mysql
- MYSQL_USER: mysql
- MYSQL_PASSWORD: admin

## Использование

1. Войдите в Airflow по адресу http://localhost:8080/
   - Логин: airflow
   - Пароль: airflow

2. Запустите DAGs

3. Таблицы в базе данных включают:
   
- Customers
- Employees
- Orders
- Products 
- Payments.

Customers хранит данные о покупателях, Employees - о сотрудниках, Orders - о заказах, Products - о продуктах (альбомах и треках), а Payments - о платежах. Каждая таблица связана с другими через ключи внешнего ключа, позволяя создавать сложные запросы и аналитику.


## Примеры запросов:

Агрегация данных: Первая витрина агрегирует данные из таблицы albums, подсчитывая количество альбомов с одинаковым названием. Это позволяет получить представление о популярности альбомов по их названиям.

Сохранение результатов: Результаты агрегации сохраняются в новую таблицу popular_albums в базе данных MySQL, что позволяет использовать их для дальнейшего анализа или отчетности.

Анализ треков: Вторая витрина агрегирует данные из таблицы tracks, подсчитывая количество треков для каждого альбома. Это помогает понять, сколько треков содержится в каждом альбоме.

Сохранение аналитики: Результаты второй агрегации сохраняются в таблицу album_track_counts, что позволяет использовать их для анализа структуры альбомов и их содержания.
